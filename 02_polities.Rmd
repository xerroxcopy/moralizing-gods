# !diagnostics off

# Polities
  
```{r polities}
# !diagnostics off
polities_df <- 
  polities_pre %>% 
  filter(!NGA %in% c("Crete", "Galilee", "Middle Ganga")) %>%  # Remove new NGAs
  filter(!PolID %in% c("IdCJBun", "IdKalin")) %>%  # Remove low-coverage polities causing bugs in C. Java)
  filter(!PolID %in% c("EsHabsb", "USIllinL", "GbEmpir", "InEInCo", "InBritP", "RuYakuL", "UsIroqL")) #Remove post-colonial polities (also see below for removing post-colonial polities from NGAs with only 2 polities)
# 299 x 11

NGAs_tidy <- levels(polities_df$NGA %>% as.factor()) # warnings maaaaay be okay.
```

# Multiple Imputations 

## ConstrMI.R

`ConstrMI.R` : from 30 NGAs in `polities`, select an NGA e.g., NGAs[1] = "Big Island Hawaii", filter SCdat and polities with that NGA, 

modern version:

input:
  - `polities_df`: a tibble of polities from `polities.csv`, minus duplicate minus new NGAs,etc. A simple list of individual polities per row, with PolID and their start/end year. 299 x 11
  - `SCdat_df`: a tibble of social complexity in 19,042 x 10, created with `01_precheck.Rmd`. NGA, Polity, Variable, Value From, Value To, Date From, Date To...
  

First, one value from a normal distribution created from ranged value (denoted by "range" in `Value Note` in `SCdat`) is used as value. Then "disputed" and "uncertain" is dealt by picking one. (Why not just use different values as is, embodying uncertainty?) Below is a dumb but fast and readble way to mutate...

```{r}
# 1

df_disputed_uncertain <-
  SCdat_df %>%
  filter(
    `Value Note` %in% c("disputed", "uncertain")
    ) %>% # includes both disputed and uncertain
  group_by(NGA, Polity, Variable)  %>% #used to include , `Date From`, `Date To` but seemed to cause unintentional filterings of polities. needed NGA instead!
  sample_n(1)  # Randomly sample from disputed and uncertain, eliminate extra rows

# 2

df_ranged <- SCdat_df %>%
  filter(`Value Note` == "range") %>%
  mutate(
    `Value From` = pmap(., function (`Value From`, `Value To`, ...) rnorm(n = 1, mean = (`Value From` + `Value To`) / 2, sd = abs(`Value To` - `Value From`) / (2*1.645))
    ) # seems like pmap() is needed. reference: http://yoshidk6.hatenablog.com/entry/2018/08/06/154117
  ) %>% unnest()

# 3: everything else

df_else <- SCdat_df %>%
  filter(!`Value Note` %in% c("disputed", "uncertain", "range")) # identical to filter(`Value Note` == "simple")

# 1 + 2 + 3

df <- bind_rows(df_disputed_uncertain, df_ranged, df_else)

# tidying sparkling joy

df_min <- df %>%
  select(NGA, Polity, Variable, `Value From`, `Date From`, `Date To`) %>%
  rename(PolID = Polity,
         Value = `Value From`,
         Date = `Date From`,
         DateTo = `Date To`) %>%
  ungroup() %>%
  ungroup() %>%
  ungroup()
# OPTION B: seemed cooler, but apparently way slower probably because of if_else
# a <- SCdat %>% 
#   group_by(NGA) %>% 
#   split(.$`Value Note` %in% c("disputed", "uncertain")) %>% 
#   modify_at("TRUE", sample_n, 1) %>% 
#   bind_rows()
#   mutate(`Value From` = if_else(`Value Note` == "range", 
#                                 )pmap(., function (`Value From`, `Value To`, ...) rnorm(n = 1, mean = (`Value From` + `Value To`) / 2, sd = abs(`Value To` - `Value From`) / (2*1.645))),
#                                 .)) # extremely slow...
                                

# OPTION C: `case_when()` extremely slow. took 3min
# df  %>% 
# mutate(
#   value = case_when(
#     `Value Note` == "range" ~ rnorm(1, mean = (`Value From` + `Value To`) / 2, sd = abs(`Value To` - `Value From`) / (2*1.645)), 
#     TRUE ~ `Value From` # Catch all statement, equivalent to `Value Note` != "range"
#   )
# ) %>% View()
```

# Join everything together

input to join:

- `df_min`: a tibble, from `SCdat_df`, actual values of polities' social complexity variables.
- `polities_df`: a tibble, to retrieve the range of years the polities were there.
- `Vars_df`


## Join 1: Join df_min with polities_df  into df_join

join by `NGA` AND `PolID`, because `polities_df` has only one `NGA` for a `PolID`, whilst some `PolID`s such as `AfGrBct` extend to other `NGA`s, hence produces many `NA` rows.

- `PolStartC`: previously `tmin`. the first century (C) the polity has already started. e.g., if 99CE, 1. 100CE, 1. 101CE, 2.
- `PolEndC`: previously `tmax`. The century the polity ended.
- `centuries`: a sequence from `PolStartC` to `PolEndC`, e.g., if `PolStartC` = 3 and `PolEndC` = 18, 3:8. needs `unnest()`ing for tidy dataframe.

```{r}

df_join <-  
  inner_join(
    df_min, 
    polities_df,
    by = c("NGA", "PolID")
  ) 
dim(df_join) # 15156 x 15. 
df_centuries_redundant <- 
  df_join %>% 
  group_by(PolID) %>% 
  mutate(
    PolStartC = (min(Start) / 100) %>% ceiling(), 
    PolEndC = (max(End) / 100) %>% floor()
  ) %>% 
  mutate(centuries = map2(PolStartC, PolEndC, seq)) %>% 
  unnest() %>% 
  mutate(
    # convert centuries back to years
    t = centuries * 100,
    PolStart = PolStartC * 100,
    PolEnd = PolEndC * 100
  ) %>% 
  select(-(World.Region:centuries)) %>% 
  ungroup() %>% # ungroup required before filtering
  filter(t >= Start & t <= End) # filter overcopied rows out of polity's existing range
  # filter(pmap(., function (t, Start, End, ...) between(t, Start, End))) %>% # alternative, not working
dim(df_join) # 39017 x 12
```

## Join 1a: filter df_join's duplicates into df_join2

filter out if t is not close to Date, for single date datapoints, OR(|, do not use ||)ã€€filter out if t is out of Date-DateTo range, for ranged date datapoints. This line is very long because consecutive `filter()`s are `and`, not `or`. Note `!is.na(Date)` isn't quite needed in the second argument because it's always `TRUE` when `!is.na(DateTo)`, but it's there for readability.

```{r}
df_join2 <- 
  df_join %>% 
  filter((!is.na(Date) & is.na(DateTo) & (round(Date, -2) == t)) | (!is.na(Date) & !is.na(DateTo) & t >= Date & t <= DateTo) | is.na(Date)) %>% 
  group_by(NGA, PolID, Variable, t) %>% 
  filter(is.na(DateTo) | DateTo == max(DateTo)) %>% # filter entries ranging  1000-1200 and 1200-1500 which result in two entries in t=1200. e.g., duplicate t = 1500 in Hawaii2 ProfPriest
  filter(is.na(Date) | Date == max(Date)) %>% # filter rounding duplicates e.g., t=1200 JpKamak Social Scale Population of the largest settlement 1250 rounded to 1200
  ungroup() %>% 
  ungroup() %>% 
  ungroup() %>% 
  ungroup() %>% 
  select(-(Date:End), -PolStart, -PolEnd)

dim(df_join2) #  37844 -> 37809 x 5. why decreased when df_disputed rows increased...?
df_join2 %>% filter(PolID == "Hawaii2") # inspectingoverlapping range:  no duplicates
df_join2 %>% filter(PolID == "JpKamak") #

```



## Join 2: Join df_min with Vars_df into df_join_shortname

social complexity variable names in `df_join` (`df_join$Variables`) are joined name of subsection and variable in `Vars_df`.

```{r}
df_join_shortname <-
  left_join(df_join2, 
            Vars_df %>% select(Variable, ShortName), 
            by = "Variable") %>% 
  mutate(Variable = ShortName,
         ShortName = NULL) 
dim(df_join_shortname) # 37809 * 5
```

## Spread: Spread df_join_shortname into df_spread

`spread()`.

```{r}
df_spread <-
  df_join_shortname %>% 
  spread(key = Variable, value = Value) %>% 
  arrange(NGA, t) 
dim(df_spread)# 820 * 70. output's got 817 * 98...


```

# PropCoded

Now we want to calculate `PropCoded`, the proportion of variables actually recorded out of the 51 Social Complexity variables in `Vars_df`. For example, when `NGA == "Deccan"`, `PolID == "InSataL"` in `t == 100` has got 24 `NA` SC variables, PropCoded = (51 - 24) / 51.

```{r}
PropCoded_col <- 
  df_spread %>% 
  select(
    Vars_df %>% 
      filter(Section == "Social Complexity variables", # there are other columns other than SC variables, e.g., freqs in `df_spread`.
             ShortName != "HeredStatus" # HeredStatus is in Vars_df, but none are recorded.
      ) %>% 
      .$ShortName 
  ) %>% 
  transmute(PropCoded = (ncol(.) - ( is.na(.) %>% rowSums())) / ncol(.)
  ) 

df_spread_prop <- 
  bind_cols(df_spread, PropCoded_col) %>% 
  select(NGA, PolID, PropCoded, everything()) %>% # https://github.com/tidyverse/dplyr/issues/1188
  select(NGA:t, colnames(output_df_min)[5:71])
```

## Verify PropCoded

Verify `PropCoded` in the paper is identical (or at least close enough) to the ones in my code.


`output` made with ConstrMI.R and `df_join` made here should be loosely identical, apart from the followings: 

1. minor `sample_n(1)` sampling errors, 
1. variable dispersion with `rnorm()`, and 
1. recoding corrections.

first, we need to create `output` that's identical with the original. to do so, Vars should be modified as done in `!MoralizingGods.R`.

```{r}
Vars <- as.matrix(read.csv('input/variables.csv', header=TRUE))
Vars <- Vars[Vars[,6]==Section1 | Vars[,6]==Section2 | Vars[,6]==Section3,] # Reduce the variables list to the Section set above

Vars[,1] <- paste(Vars[,2],Vars[,1])
```

Now run `ConstrMI.R` and come back.

tibblize `output`
```{r}
output_df <- output %>% 
  as_tibble %>% 
  mutate(
    Date = as.numeric(Date),
    PropCoded = as.numeric(PropCoded)
  )
dim(output_df) # 817 x 98
# minimal. https://community.rstudio.com/t/drop-all-na-columns-from-a-dataframe/5844/3 
output_df_min <- output_df %>% 
  select_if(
    function(x) {!all(is.na(x))
    }
  ) 


# profPriest in Hawaii2 t= 1200 is dropped in df_spread_prop, while it's available in output_df_min at 0.1.
```

### Visualize


```{r}
df_inspect <- df_join2 %>% 
  filter(NGA == "Sogdiana", Variable == "Bureaucracy characteristics Full-time bureaucrats")
df_inspect2 <- df_join2 %>% 
  filter(NGA == "Deccan")

df_inspect %>% 
  ggplot(aes(x = t, y = Value, colour = PolID)) +
  geom_point() +
  geom_line()
```

Ideally, points should be all lined up to `y = x`.


```{r}
left_join(
  df_spread_prop %>% select(t, NGA, PolID, PropCoded), 
  output_df %>% select(Date, NGA, PolID, PropCoded),
  by = c("t" = "Date", "NGA", "PolID")
) %>% #View()
  ggplot(aes(x = PropCoded.x, y = PropCoded.y / 100)) +
  geom_count(alpha = 0.3) +
  scale_size_area() +
  geom_abline(slope = 1, intercept = 0) +
  coord_fixed()

# some entries don't fit. why.
df_spread_prop %>% filter(NGA == "Kansai") %>% View()
output_df %>% filter(NGA == "Kansai") %>% View()

``` 

### who are still not identical?


```{r identical-police}
df_discrepancies <- 
  left_join(
    df_spread_prop, 
    output_df %>% select(Date, NGA, PolID, PropCoded),
    by = c("t" = "Date", "NGA", "PolID")
  ) %>%
  filter(round(PropCoded.x * 100, 1) != PropCoded.y) 

df_discrepancies %>% 
  select(PropCoded.x, PropCoded.y, everything()) %>% 
  mutate(PropCoded.x = round(PropCoded.x * 100, 1)) %>% 
  View() # 27 rows


df_spread_prop %>% filter(NGA == "Susiana", t > 600) %>% View()

output_df %>% filter(NGA == "Susiana", Date > 600) %>% View()

```



inspect by table:

```{r}
full_join(output_df %>% select(NGA, PolID, Date)), 
          df_spread %>% select(NGA, PolID, t),
          by = c("Date" = "t", "PolID")) 
# Vars_df %>% filter(Section == "Social Complexity variables") %>% arrange(ShortName) %>% View()
```

The `df_spread` got 3 extra rows not contained in `output`: IrQajar and TrOttm5 for `t` = 1800 and 1900. ISSUE.


inspect by plot:

```{r fig.height = 20, fig.width = 20}
output_df %>% 
  filter(NGA == "Deccan") %>% 
  gather(key = Variable, value = Value, -PolID, -NGA, -Date, -PropCoded) %>% 
  ggplot(aes(x = Date, y = Value, colour = PolID)) +
  geom_point() +
  geom_line() +
  scale_colour_viridis_d() +
  facet_wrap(~Variable, scale = "free_y") 

df_join_short %>% filter(NGA == "Deccan") %>%
  ggplot(aes(x = t, y = Value, colour = PolID)) +
  geom_point() +
  geom_line() +
  scale_colour_viridis_d() +
  facet_wrap(~Variable, scale = "free_y") 
  # theme_tufte()

```

